# 1.  2024/4/7

本周学习主要从以下几个方面

## 1**.**调研整理各种“内生式”AI的资料

先说结论：关于“内生式”AI报告，词条很多，主要以数据驱动，知识驱动为主。但是实验结果几乎没有，几乎都是把整个大语言模型的基本概念串讲了一遍，然后强调一下知识与数据共同驱动的重要性。目前没有看到过比周志华老师abductive learning更有价值的。

主要困境有：

1. 数据驱动和知识结合算力开销相对纯数据驱动很大，缺乏有效的结合方式。

   ​	以周志华老师的abductive learning为例，相同的数据下，结合知识驱动需要多几倍到几十倍的算力，目前数据驱动没有到推不动的地步，所以没有动力去做如此性价比低的事情。

2. 在知识驱动层面上，无法保证知识框架能描述所有知识。

   ​	比如说，命题的逻辑推理，如果涉及到自指会产生悖论。

3. 大模型如火如荼，目前资本寻求的是大模型的落地实现盈利，要先把这一轮投的钱收回来。

我们为什么要搞“内生”？其实并不一定是“内生”，而是解决一些纯数据驱动无法解决的问题

我的想法：

1. 通过多领域融合给问题出一个推断，并不一定要涉及到逻辑推理。

   ​	福尔摩斯在断案时，会结合化学，解剖学，地理学，心理学等去寻找线索，普通人很难涉及多个领域，但是大模型可以更多的涉及多个，乃至甚至几百上千个领域的融合。

2. 信息整理与分类与解释性，并不直接推断，而是给出建议

   例如，我想知道A股明天的涨跌，没办法给出确定的保证，但是大模型可以通过分析，找到尽可能多的影响信息。比如，央行放水，对于股票上升有利；人们消费欲望不强，对于上涨不利；楼市资金流出，部分流入股市，对上涨有利。最后再分析各自影响因素的大小，可能还没考虑到的情况，过去与之类似的情况，其中存在矛盾的点等信息，把最后的判断交还给人。类似于，谋士给出局势判断，上中下三策，但是最后决定权还是交予主公。

## 2.参考dubbo实现自定义的RPC框架

1. 主要涉及：Vert.x、Etcd、SPI 机制、负载均衡、容错机制、重试机制、注解驱动、动态代理、 反射的运用实践
2. 初衷：之前学过的一些东西不用都快忘了，做一个开源项目巩固一下，也算是丰富一下自己的简历，后续完善之后也可以供其他同学参考学习。
3. 预期与进展：预计花费一个月，在不耽误其他事情的情况下，抽空做。目前已经完成基本框架的搭建，自定义序列化器，tcp通信的开发。开源地址：https://github.com/Zest7/RPC-s 



# 4/14

## 1.大模型相关跟进

1.上周提到多领域融合的问题，这周跟进了一下。大语言的模型融合是一个复杂问题，一些传统的博采众长的方法很难行得通，因为本身大模型的训练资源消耗就很大。目前觉得比较有前景的是使用**遗传算法进行模型融合**，不去分析模型结构，仅仅是通过参数，结构等进行拆分混合，然后进行遗传淘汰。目前已经在一定范围内取得了效果，例如llama2和qwen 72b遗传的结合体，在整体表现上超过父本。 

2.马斯克新开源的Grok-1.5V，X公司公布的测试是超过了GPT-4V，这里就不谈实际性能了，因为几乎每个产品都有吹的成分，重点探讨一下之后的方向。

参数量达到314b（llama2，qwen最大的版本仅仅72b），运行显存预计630G以上。之前的模型已经够大了，但是现在大公司还是在”大“上持续进行追求，我个人推测是希望一力降十会，先将其他普通玩家出局，然后再考虑应用盈利。

再考虑的远一点，这样不计成本的投资背后可能有更深刻的含义。以下是我大胆假设：**美元霸权**目前依附于石油定位，目前国际局势的影响（巴以冲突可能的升级，俄乌冲突的可能的升级）带来的震荡对美元的稳定性带来了冲击（国际金价上涨，就是资本规避风险的铁证）。对此，美元需要新的锚定物，或者说需要更多的锚定物，近年来”**云计算**“概念的火爆，在学术界有一部分人认可”**算力**“将成为一种重要战略资源，能对比石油，天然气。但是问题在于，廉价的算力大家都有（从战略意义上讲，只要有廉价算力仅仅依靠产电；类似于炮弹只依赖火药等原材料），美国无法占据主导地位，所以”**算力**霸权“****对于美国没什么好处。但是高端算力只有美国目前有，以现在这个Grok-1.5V，训练可能是200台 h100训练的；考虑到多卡混合计算的通信等成本，类似于升腾卡目前的性能，不可能能达到这个算力（纵使1000，1万张都没用）。如果超大大模型得到应用，**高端算力**有了需求，便有了”**算力霸权**“的可能性。

## 2.自定义RPC框架

本周优化了tcp传输，解决了半包和粘包问题；

使用Etcd作为注册中心，实现了服务注册，发现，注销等，后面涉及到高并发的问题肯定是需要一个注册中心来管理的。

## 3.论文进度

实验进度：调整环境大小参数试了一下，目前算法并不能很好的迁移不同的环境

论文撰写：第一章节 Introduction和第二章节 Relate work初稿完成（还是比较糙的，后续会有修改）

# 4./21

## 1.大模型相关跟进

之前的工作有说到，目前大模型几大提升方向：

（1）提高模型的大小

目前meta在这个方向走的比较远，上周开源的Grok-1.5达到了314b，4月18号开源了llama3的8b，70b版本，目前正在训练的llama3最大有405b版本。看样子马斯克要在**军备竞赛**这条路继续往下走

（2）多模态

多模态主要方向包括了文生图，识图，语音识别，语音生成等。以目前行业龙头**openai的GPT-4V**和**meta的Grok-1.5V**举例，个人认为在应用上完全足够用了，或许很快大公司就要开始卷AI应用了。

效果参考链接：[Grok-1.5 Vision Preview (x.ai)](https://x.ai/blog/grok-1.5v)或见附件

（3）结构性优化性能

在不改变模型大小的情况下优化，除去之前老生常谈的量化，思维链等方式，最近谷歌提出了**采样率**优化的问题。

参考论文：https://arxiv.org/pdf/2404.01367.pdf  或见附件

最后的结论：是较小模型的采样效率更高。当给定了采样预算时，较小模型的会优于较大模型。

我的想法：考虑到最后的工业化应用的部署，最后的大模型的模型不会是越大越好，综合性能和开销的情况下，会是一个凸函数。这个最佳的模型大小或许是50B，或许是500B，目前并不能确定。

## 2.论文进度

本周主要完成了system model，Problem Formulation的撰写。上次组会也和孙老师交流了，大体思路没啥问题，目前是一些具体的细节处理进度太慢



# 4./28

## 1.大模型相关跟进

上周主要讲到，跟进领域模型

撇开不同领域的差距，从共性出发，领域模型有两种实现模式

### 1）.使用对应模型的语料进行训练

这种实现方法基于一种朴素的理念，假设语料总量固定，A模型全部为对应领域的语料，B模型为各个领域混合语料，A模型在对应领域内会有更好的表现效果。

在这个假设下，确实有比较好的效果。但是语料总量和模型大小并不是固定的，目前领域模型大多是7b，13b的模型，llama3，gpt4等都超过了100b，不具备实际对比意义。

当然，可以换一种思路，假设目前有一个100b大模型，我们直接在这个模型基础上增加语料进行调参，理论上可以强于原模型。但是没有找到相关研究，猜测是这样的操作不具备研究意义，没有创新点；实用意义也不确定，具体提升了多少，从收益上是否划算；或者其实有公司研究，但是这个具体参数有商业价值保密。

### 2）.借助外部资料

一种实现方法类似于专家系统，大模型变成了与用户沟通的桥梁（设计模式中的代理类），实现的方法还是专家系统那一套，性能也取决于内部的模型。

另外一种方法，使用embed（嵌入）的方式，将领域对应的核心语料嵌入作为prompt（提示），这种方式，我个人感觉不具备太多研究价值，只能算一个小优化。举一个例子：假设考察某人一道数学题，提示他这是考数学，考计算，不是脑筋急转弯，考的知识都是学过的，从统计概率上确实可以增加得分率，但是该不会还是不会，不是说给更多（更好）的提示能解决问题。



也正是这两种模式都出现了一定问题，目前领域模型探讨热度有所下降，之前一些拿到风投的公司做的领域模型，也没看到有什么太好的产品。

## 2.论文进度

Problem Formulation思路整理，之前问题描述还有一些问题，表述的比较混乱

# 5/12

## AI for Science

前面提到AI除了作为简单的工具，还应该能进行自主科研。对此有了AI for Science的概念，目前查阅到资料主要相关于（1）蛋白质结构分析 等生物制药,（2）新材料研发，（3）核聚变等前沿物理，（4）气候预测等地球模拟和天文 探索，（5）飞机引擎，汽车动力结构，建筑等工业设计等领域。

个人观点：目前有的AI for Science的范式，有逻辑，却没实质进展。因为，智能结构，根本不是这种什么范式的。这些范式，是辅助，并不是核心，**范式应当是有一定落地成果后，总结归纳向其他领域或者方向扩展**。目前最需要的是走出第一步，以（飞机，火箭）引擎为例，分为三步：AI生成方案，然后AI模拟仿真判断，人类专家评估。AI生成的优势相对于人类专家，主要在于灵感源源不绝，如果能实现生成方案到模拟仿真判断的全自动，至少可以生成有参考价值的方案。当然这肯定不是最终形态，但是需要先迈出第一步。

搜索资料的一些小感悟：去宏观设计概念的报道，资料很多，在关键领域去突破的反而比较少。也是由于利益使然，现在的科研不太允许失败，或者说普通人承受不了失败的代价。

## 工作行情

最近也是师兄师姐找实习普通不是很顺利，出于自身的焦虑，随意的投递了一下简历，以及和两位hr（一个华为杭研院的，一个字节剪映）沟通了一下。

1.大厂基本都在一边疯狂裁人，一边招应届生。意味着，找到工作也有可能在一两年后，因为不具备“性价比”离职。

2.目前学历贬值挺严重，例如华为杭研院测试，之前都是招双非本，现在基本是985硕才能进面，属于企业的“工程师福利”。

3.之前大厂挺看重学习能力，发展潜力。只要有潜力，例如有高质量论文，基本功扎实都算加分项。目前是有潜力的人太多了，所以除了要有上述的潜力，还要有对口的项目经验，科研成果等。越来越卷是必然了。



# 5/14

## 宋老师讲座总结

讲座内容非常常规，就是什么是智能，近代AI发展等等，算是对外行的科普，并无借鉴意义

最后几分钟的提问交流环节，宋老师提到了他们团队现在的研究，大模型多智能体的合作，例如：在一个环境中，有10个智能体（大模型控制），分别扮演医生，教师，司机等等，然后正常这样运行，看看能不能培育出新的东西，例如数学家。但是目前只是概念，还实现不了，宋老师的原话是“但是目前还有很多细节问题需要处理”。简单调研了一下，宋老师的学术研究和项目，近两年主要是卷积神经网络，CV那一块，确实这方面还没出成果。

我的观点：宋老师现在的研究，是**内生式AI**的一种思路。我们人的创造是怎么来的，来自于生产实践。同样的，如果我们想要AI能创造不一样的东西，不应该是我们要求，而是让AI自行的加入生产实践当中。与人类社会相比，这种多智能的优势在于运作效率，例如，在足够算力的堆叠下，只需几个小时，就完成了类似人类一生（几十年）的生成实践，所以这样的模式是有潜力发展出人类目前认知以外的知识的。当然这只是一个思路，落地很难，但是这个思路完善一下，做一个demo，或许会有投资人有兴趣呢？

# 5/19

## 大模型多角色Agent协同合作

之前提到的宋老师的研究，找了一下相似的一些工作。比较主流的metaGPT通过为不同的Agent分配**角色与任务信息**，并配备相应的**工具插件**，从而完成复杂的任务。例如：执行一个调研任务，一个agent具有联网搜索能力，进行资料收集，一个agent专门有格式化的预训练，进行排版，一个agent进行审核......通过把一个复杂问题进行分解，然后解决一个个子问题。

在此基础上，如果要更进一步，需要解决的问题有

1.多agent能够自主分配任务。优胜劣汰，agent具有不同的属性，会因为环境，分工能淘汰变化。

2.agent能自主产生需求，新的需求带动新的发展。类似于人类社会的发展，新质生产力，带来新的社会变革。

## 论文

把实验部分之外能写的都写了，写的时候又有了一些新想法。想着改一些实验环境，重新做一下实验，然后自己墨迹也没整完。

## 复习考试

复习《最优化方法》



# 5/26

## 李飞飞认为AI 没有感觉（sentient）能力

李飞飞列举了大量示例来证明这一观点：

1.深蓝，虽然这款下棋程序可以击败世界冠军，但如果房间突发意外情况如着火，深蓝不会有停止游戏的意识，而人类会有。

2.当人类产生饥饿说出「我饿了」时，人类和 LLM 背后所隐藏的行为链条是完全不同的。LLM 只是产生「我饿了」这个字符串的事实，它没有身体，甚至不可能有饥饿那种感觉。

因为李飞飞和John Etchemendy的影响力

我感觉这种议题的讨论还挺奇怪了，一直讨论这样的问题，最后的结果肯定是哲学化

# 生物领域大模型Evo

Evo 由Arc Institute、斯坦福大学和TogetherAI的研究人员开发，能够泛化生物学的基本语言：DNA、RNA 和蛋白质。它能够从单个分子到整个基因组规模（超过`650 kb`）进行预测任务和多模态长序列生成设计。

简单一点解释，就是可以生成指定功能的蛋白质（DNA），或者根据给的蛋白质（DNA）结构分析作用。

单纯说这个模型没有太多意义，讲讲整体调研的一个主观感受吧。调研了生物，化学，精密机械各个领域的“大模型”相关的AI技术，我个人感觉，大模型不管怎么说都是基于数据的，目前我们所应用的知识和大模型所能理解的数据还有一定差距。类似生物学这种，就是碱基对/DNA等排列组合，空间结构等，这样的数据就相对好拆分，所以有更多的数据也更好利用大模型。而例如火箭这种，涉及精密机械，新型材料情况会更加复杂，本身都没法把所有特征转化成ai可以理解的数据。举个例子，1平方米的普通钢板，它的密度，熔点等可以转化成数据，但是疲劳破坏指数等信息呢？把一个具体的物品，转化为n项指标后，其实数据信息是被压缩了，可能忽视了没考虑到的指标，AI从指标中的数据学习，那也不可能突破这些指标的描述。

各个领域，（客观世界的）物质转化为数据的信息不同，所以利用大模型的效率也不同，而且这种需要人工处理数据的方式不可能超出数据的限制。应该让大模型能够自主获取数据，不仅仅规定的数据类型，而是让大模型能自主创造新的数据类型。例如，人可以感受到图像，声音，文字信息；而一些动物可以感受到次声波，因此可以获取人类没有的信息预测地震。如果大模型能探索到最适合它的数据形式，可能会有新的突破。



# 6/9

## 智能体工作流的应用

近日，斯坦福大学吴恩达教授在一次演讲中表示：“基于 GPT-3.5 构建的**智能体工作流**在应用中表现比 GPT-4 要好。AI 智能体工作流将在今年推动人工智能取得巨大进步，甚至可能超过下一代基础模型，这是一个值得所有人关注的趋势。”

什么是工作流？拿写论文举例。

​	1.传统方法就是：写一篇关于ai范式的论文

​	2.工作流则是：上网查找关于ai范式的资料；整理资料；写初稿、读初稿，并思考哪些部分需要修改；修改你的初稿并继续推进。

这符合我们的生活体验，有些人可以凭借良好的流程胜过那些比自己聪明的人。当然，这个工作流的流程如何设计，肯定也是前期基于人工数据，后面模型可以自己学习。

其实这种方法和prompt提示工程有些类似，只是方法更加系统了。此外让大模型自己思考，最终也会类似ac网络最后达到一个平衡收敛，所以肯定不会像吴恩达说的那么理想。

一些技术细节缺乏数据支持，有待考究。

## AI for Science

继续前面AI for Science，前面提到，整体的概念太庞大，需要以点破面，先有一个demo。

一个比较朴素的想法：在仿真环境下，大模型基于已有数据进行探究，以无人机飞行为例，假设如下

无人机有机翼大小，总功率，机翼功率，重量......等几十个参数，在过去的实验中，有一系列数据和结果构成一组组数据。大模型将通过已有的数据生成最佳参数。

这里有一个显而易见的问题，大模型无法真正理解每个参数的含义，或许在它看来只是一个参数，那这样用大模型处理和使用传统的机器学习处理有什么区别呢？

结合前面讲到的工作流，我们的大模型肯定不是光从参数数据上学习，而是通过自主思考来决定需要有哪些参数，已有的数据应该怎么样利用（等于是让无人机自行进行实验获取数据，并进行数据处理）

开始是打算使用AirSim进行仿真模拟，一用就发现问题了。首先是平台并不支持如此复杂的设计，这至少是可以解决问题，可以再看看其他平台，或者自己编码进行一些设计。最重要的是，仿真平台的结果取决于仿真环境的设计，例如：在仿真环境中的定义，速度=功率/重量，那么实验结果肯定完全受制于这个设定，这有何意义？

抛开这部分不谈，我们只讨论大模型学习的这个过程，基于一个朴素的想法，至少对于大模型它是不知道我们环境的设定的，既然它能在仿真中找到规律，也应该能在现实世界中找到规律。那么最大的问题变成了，仿真环境很难设计的像现实世界一样的复杂，在简单环境中训练出来的模型，不一定适用于复杂环境。

回到最开始的问题，我们只需要有一个demo，所以一些具体问题不必细究。只需要仿真实验中，大模型能通过思考（结合前面工作流的），自主进行流程设计，完成既定目标。那第一步就完成了。

## 实验部分

最朴素的想法：实验环境提供各个操作的api，大模型通过环境给的输出，调用api进行操作，进行交互。

第一步就有问题，大模型(测试用的qwen)没法很好理解环境中各个api.....直接使用等于是用prompt提示大模型这些api的作用

使用langchain的方法（去年11月的工作，大模型langchain），进行embed，将api嵌入，但是效果还是不好。我怀疑大模型会根据api的名称来猜测用法，会收到最开始训练的影响。例如 **airsim**.WeatherParameter(),按照我对大模型token切割的理解，大概会切成airsim,Weather,Parameter,然后之前训练的数以百亿计的语料中肯定有很多airsim,Weather,Parameter，然后大模型就把之前的对于这三者的理解搅合到一起了。。。（大模型一旦涉及到自己去调参，问题就茫茫多，而且基本靠猜）

目前的想法得先微调大模型，或者试试其他的“号称”预训练对api。还在找方法。



# 6/16

之前的想法主要有两个问题：

1.大模型并不能很好的调用函数，如果可以实现的很好，应该也会先用在智能家居等方面，所以这一步迈的还有点大。

2.如果能够在仿真环境中表现的很好，到底有没有用？比如周志华的反译学习，他其实也做了demo，在法律条文上的应用，实际上是没引发什么波澜。

光想不是一个好办法，只能说带着这些问题，继续看看别人的工作。简单介绍一下几个我觉得比较有意思的。

## 文生视频大模型「可灵」（Kling）

前段时间Sora火遍了社群，6.12号快手推出了可灵，实测效果据说比Sora更好（可惜我没有测试资格，很难抢）

还是比较惊喜的，毕竟之前的大模型都是被嘲讽“国外一开源，国内就有创新”。

现在看起来或许在很多地方可以追平，甚至领跑。

## 互动智能体深度透视人类隐式意图

来自面壁智能的一项研究

这项研究主要研究：智能体如何捕捉和解析人类指令的隐式意图并作出反应，提高智能体的隐式意图理解能力。

举个例子：  询问AI这附近最好的餐厅是哪家？   AI并不知道这个附近到底是什么样的范围，走路能到还是开车十分钟内呢？又用什么评价好坏，评分最好就是最好么？

以往，这样的问题，AI都是利用数据和算法给出一个loss最低的答案，但是并没有去思考这个问题本身的描述是否有问题。按照比较好的情况下，AI应该主动询问存在疑惑的地方，以此来达到一个更好的答案。

具体的策略是加了一个中间模块，用来判断问题，以及如何提问更好的回答





# 6/23

# BSD

**BSD**定义：仅从外部输入输出观察而不是正式的程序代码生成 CPU 设计的电路逻辑，该逻辑由称为二进制推测图 （BSD） 的图形结构表示。

我用比较通俗的语言解释就是，给定输入输出，由大模型自动生成电路逻辑。

以最简单的门电路为例子，有两个开关，两个灯泡，我们希望打开第一个开关第一个灯泡亮，打开第二天开关，第二个灯泡亮，然后大模型来设计这个电路，当然这里设计是cpu的电路，里面的过程复杂很多。

**涌现**：论文和报告中没有提到涌现，大概率就是当模型不够大时设计不出来复杂的cpu电路逻辑，到了一定规模就可以设计出来了。这种涌现情况，我觉得还是可以用评判指标来解释，如果是以电路逻辑的线路来衡量大抵是平滑的，而以准确率为标准衡量就会有一个“质变”，然后被称作涌现。

**白盒可解性**：他这边说的可解释是生成的电路是可以看到的，我们有了电路就知道输入到输出的一个过程。但是大模型怎么生成这个电路，还是不可解释的。这种所谓的可解释性，确定不是语言艺术？



总之，这个BSD的成果就是5 小时内生成了工业规模的 RISC-V CPU。和那种预测蛋白质模型的大模型没有本质区别，可以理解为设计逻辑电路，设计CPU的大模型。



不过既然能用大模型设计CPU了，从这个角度来说设计航天器等精密仪器应该也是可以的。

## 我的一些想法

这个里面疑点太多了，不说别的吧，从结果导向来说，这个研究发布于2023.7月，也就是大模型热度很高的那一段时间。后续就找不到相关研究了，有点蹭热点的嫌疑。都快一年了，应该也有新的成果了。

实验方法的模拟，修正之类的，很像强化学习的那种模式，而且测试全部都是外部输入输出示例，确定这个没有学习到过拟合？这很不合理。通过蒙特卡洛来模拟生成的数据那种，怎么就达到13个9的精度了，很像是示例全部过了。

前面提到蛋白质模拟相对简单，航天器相对困难，很大一方面就是搜索空间的大小方面。注意力机制，深度学习等等，本质上也是一种启发式搜索，其实我们人的思考方式也是类似。



# 6/30

## 有关大模型的质疑

 	 Super App 仍没有出现，英伟达股价暴涨又暴跌，AI 巨头们尚未找到可行的商业模式。随着第一轮AI相关的投资烧完，质疑声也越来越多，最近**Nature**新登了一篇论文《Language is primarily a tool for  communication rather than thought》唱衰 LLM，把这次质疑推向了高峰。

​	论文的中心思想就是标题，"语言是沟通的工具而不是思考"，但语言并不是复杂思维（包括象征思维）的先决条件。语音只反映而不是产生人类认知的标志性复杂性。论文主要用生物神经学相关的知识和实验论证了这个观点，这部分不过多介绍。

​	在上述论文的观点中，先有了复杂的思考，然后语音只是表达出来这个思考。这个论据给了批评者们一些论据。以 Yann LeCun（杨立昆，图灵奖获得者） 为代表的一种声音认为，LLM（大语言模型） 不具备理解、记忆、推理、规划这四项智能的基本特征，是通往 AGI 的一条歧路。LLM只是把数据提炼了，能够很好的将问题和答案匹配，研究LLM无法获取数据的内在本质。举一个不太恰当的例子，太阳升起了，公鸡打鸣，我们研究公鸡打鸣的机制可以知道升起的时间，但是没法发现星体运动的客观规律。

## 我的一些想法

别人批评就是我们改进研究的方向，也正是目前LLM的一些弊端，才要做内生AI。但是从周志华的反绎学习到自动化所团队的BSD等，都有点擦边球的意味，其他更多的研究者更只是喊喊口号。我们可以很容易的找到别人研究的弊端的不足之处，但是自己无法做出一个看起来有前途的方向。

回到我们之前说的精密仪器的设计，比如用LLM设计一个发动机，难点在于如何把客观世界的数据参数表达为LLM中的数据，如何设计一个能囊括所有机械结构的系统？相较于结构相对简单的蛋白质（只是碱基对的排列等），BSD（直接就成电路板了，而且实验过程存疑）。倒是可以利用现有的一些模型，风阻模型，结构模型等，套用LLM设计一个机械元件，不过这就类似BSD的设计了，明眼人很容易看出来问题，完全算不上创造。

我想也没有必要丧气，本来相对容易的课题别人肯定做完了，现在发现一些路走死了就当排除法了。

# 7.7

## 注册资料辅助评估系统

建设方案已经比较详细了，整体的业务流程没啥问题。主要讨论两个点

### （1）爬取外部数据库到本地数据源

1.人为设定规则，将外部数据源转化为本地SQL或者NoSQL的存储方式，规则集构建麻烦，需要很强的专业能力理解。

2.使用传统机器学习的一下方法进行评分，分类等。也需要制定评价指标，但是相对第一种方法考虑的少一点。

3.大模型工作流，指定提取流程。例如第一步，列出几项重要指标。第二步，对于安全性/价格（几个重要条件）进行评估。第三步，整体评估。等于也是制定一个流程。

当然这只是扩宽一下思路，实际中可以结合业务更加精细化的处理，以及结合使用。比如有一个药物有主要成分A，B，C；功效1，2，3。可以用规则集保存主要成分和作用的原始数据，传统机器学习的方法对药物进行聚类分析，而其他的描述文本经过大模型处理，提炼出最重要的几个点（每个药物不一样）作为备注。这样查看一个药物的时候，可以看到关键信息，和其他药物的对比，以及一些可能比较特别的描述。

### （2）药物的查询

药物的查询除了传统的精准查询，模糊查询一些方法，也可也利用大模型隐式意图挖掘更加有效的交互

同样的也可以根据业务进行细分，比如退烧药，这种很成熟的肯定有了具体的量化指标，查询的时候可以给出一个比较具体的结果。而如果是一些提及比较少的，本身也没有太多规则设定，则可以用大模型结合相关材料进行概况，（在设定好的几个指标约束下）给出建议。



整体思路就是把传统方法和一些比较新的概念杂糅起来，看上去更加新颖，有发展前景。没有大模型整个业务流程也是可以进行的，大模型只是补充，这个很好动态调整。完全可以初期大模型的应用只是一个设想，先把流程跑通了，后续只是一个添头。

### 关于不想用大模型

什么是大模型本来就是一个比较抽象的概念，多大算大？就好比从机器学习到深度学习，多少网络才算深？如果我们只是解决具体业务的一个小模块，也就是领域模型，不一定需要多大，那还算大模型么？只能说transformer架构的机器学习。所以这里完全有其他说辞，比如注意力机制与xxx相结合，智能推荐xxx。

## Sovit_GPT

就是语音合成的开源项目

主要是参看了新版本的一些特性，以及新的一些调参的结论，做了一些实验和对比。

比如说，训练样本应该比较具有特色（手动打标，以及挑选样本），切割方式的不同的影响（太长容易漏文本，太短容易过长停顿）等一系列影响，测试最后不同的生成结果。

最后的结果难以量化，主观感觉上效果好了一点。没有合适的量化标准，其实做不同的实验调参有点瞎搞，凭感觉。

## 学习Sa-token

一款开源的权限管理系统，使用Sa-token实现了单点登陆，角色-用户层级的权限管理。

后续打算用Sa-token实现组织-组织层级（权限）-个人更复杂的组织架构对于更复杂业务的权限管理。

# 7.12

## 注册资料辅助评估系统

比较靠谱的解决方案没有找到，有些存粹是根据业务去人为定义规则那肯定不行，听起来都很low。

之前周志华组做过类似的东西，Abductive Learning在盗窃司法量刑中的应用，这个跟注册资料去评估药物的需求在本质上还是很接近的。

这项工作发了一篇ICDM CCF-B类但是也是数据挖掘方向的顶刊了。当时的时候复现代码没成功就没搞了，现在又返过去看一看，至少会有一些值得借鉴的想法，至少是矮个拔将军了。

简单概括一下论文的内容，之前在组会上分享过Abductive Learning玛雅文字破解的流程（这个文字描述太难了，我只能当老师还记得部分内容了） ，属于是把数据和逻辑推理都利用上了，这篇论文就是利用类似的方法，在法律条文上进行推理，根据他们的说法这种方式在拥有大量未标准数据，以及一部分规则的时候比较好。显然，他们做的司法量刑和我们想做的药物注册资料辅助评估都属于这种类型。

难点在于复现论文，我还没复现出来，再整整吧，发的Email暂时没有人回复。

我想的是，只要能搞出一个大概的东西，有点噱头可以说一说就行了，原计划AI就是给这个系统锦上添花嘛，而且也没有用GPT系列很符合甲方的想法本身Abductive Learning肯定是存在一定问题的，但是这不妨碍它还是有一定的进步性。

## 分布式数据库替代小型机

讨论中谈到银行使用IBM的小型机存储数据，但是太贵了，可能有替换的需求。

调研了一下，这属于历史发展问题，除了银行很多行业都有类似的需求。比如阿里巴巴从2013年棱镜门事件后就开始去IOE（IBM的小型机、Oracle数据库、EMC存储设备）化，现在已经有了成熟了分布式数据库存储的落地实现。

前面提到数据恢复操作很多都是通过记录命令的逻辑日志，有先后顺序，所以转分布式之后会比较麻烦。诸如此类的问题有很多，并不仅仅体现在通过逻辑日志恢复数据，数据的转存，服务不中断等也是问题。一系列复杂问题去修改的成本太高。目前比较好的办法就是重构，但是这样会影响之前可以正常运行的业务。所以公司的策略基本上都是已经有的就不动了，新的业务就用更加先进的设计。

综上，替换数据库可能是一个伪需求，因为所带来的开销都超过重新开发一套。可能银行一些领导也不关心这些技术，就想着花点钱维护一下，但是其实真正把需求复杂度和花费给他算明白，也是打退堂鼓的。

## 基于Sa-token的权限管理框架

扩展了一点功能点，想着支持更加复杂的组织架构和更精细化的权限管理。

有时候一个很简单的想法做起来还是挺复杂的，细节是魔鬼，比如我想着把mangoDB整合进来就导个包照官网文档写一写就行，但是实际中就是会有很多小问题，版本兼容性或者底层的一些设计导致实现的效果并不符合我的需求，一来二去就花费了不少时间。

王老师您带我们做项目往往都是从顶层设计上来理解，高屋建瓴是一种很好的方法。在社会需求上，年轻人还是得做一些很具体的细致活，所以我还是花费一部分时间做一点看起来简单的活，不能荒废了基本的code能力。



# 7.21

本周主要是调研AI for Science 相关工作

周六爬山，强度没控制好，周日躺了一天，周报是周一（7月22日）补的。

# 「自主进化」的Agent

https://arxiv.org/pdf/2406.18532

### 前言

作者来自波形智能、浙江大学、和北京航空航天大学。共同一作中，周王春澍是波形智能的联合创始人和 CTO，欧翌昕是浙江大学硕士二年级，丁盛为为北京航空航天大学四年级本科生。

看到自主进化，我就觉得很新颖，看完之后有一点失落，不是我想的那种“自主进化”,应该算是自动寻找一些超参数，但是其中的

### 目的

目前大模型的使用过程中，prompt的编写需要用户思考，tools的使用需要工程师对算法模型进行预设，而不同的大模型底座对于prompt，tools等的需要又不同，这项工作的目的就是为了解决这个问题，让大模型能自动解决这些参数的问题。

结合现实场景，我举一个例子，我想让大模型帮我写一篇周报，给它原始数据参考，它可能不能给出一个满意的结果，需要在prompt中给出格式，内容量等等一系列提示；而理想的人工智能应该能自主判断这些需求。

### 核心内容

这项工作首先将基于大模型的智能体解构为三个主要元素，即 prompts, tools, 和 agent pipeline。受传统的神经网络启发，将prompts 和 tools 看作是这个 layer 的 weights，智能体的 workflow/pipeline 则可以看作是网络的计算图,之后通过一系列近似/建模的手段，使得传统的反向传播和梯度下降可以应用于这一套系统。

### 实验结果与复现

这篇论文开源了，而且结果很好复现。但是问题也很明显，测试集属于精心挑选过的那种。目前这个方法只适用于小部分常见，例如论文举例的创意写作。

[aiwaves-cn/agents： (github.com)](https://github.com/aiwaves-cn/agents)

### 收获与感想

我想到了之前看的一句话，讽刺意味  “优秀的论文在公开数据集上籍籍无名，在私有数据集上大显神威”

现在对于大模型或者其他智能研究的方向，没有统一的标准，基本大家都是只说好的不说不足，所以会营销会造势就是很重要。

当然这个工作其实还挺不错，有一定的创新度，有很多工程处理的细节还是有难度的，只是大家看论文都不看这种，都是看idea，所以作者也在标题上面玩了鬼，我感觉就是搜超参数，和自主进化不是一个概念。

很多研究都挺扯淡了，前面说的挺牛，挂一个xx很牛的人，一点细节都没有。给我的感觉就是，拍脑袋想了一个idea，然后具体实现啥的根本没有往里了去想。

比如说：诺贝尔主托马斯·萨金特教授：大模型是记忆还是理解？  

   [专访诺奖得主：大模型是记忆还是理解？ (qq.com)](https://mp.weixin.qq.com/s/V5fdlHz6JBQQNXsIVpVvSQ)

从因果模式上去分析的大模型，讲的很有道理，但是对于实际工程发展找不到有用的落脚点

# 中科加禾-异构原生 AI 算力

7 月 20 日，AI 基础设施创业公司中科加禾正式发布了第一代异构原生 AI 算力工具。

崔慧敏，中科院计算所研究员，清华本硕，中科加禾创始人及CEO。

所谓异构原生 AI 算力工具，类似于在底层显卡上的操作系统，可以屏蔽底层不同显卡的细节，进行统一操作调度和优化。华为的鲲鹏也是在这个生态位，不过华为这个是针对它自己的卡设计的，不兼容不同的卡。

崔慧敏称：

*「加禾异构原生 AI 算力工具」兼容多种国产 AI 芯片，为屏蔽芯片差异提供了高性能的统一接口。在异构原生平台的基础上，AI 算力集群在大模型推理上的时延可以降低 3-74 倍，吞吐率提升 1.4-2.1 倍，能效比提升 1.46 倍，可支持 340B 参数量的稠密大模型，以及 640B 的 MoE 大模型。*

发布会的表述总是有点吹牛，时延降低3-74倍都不知道咋来的，也不知道和谁比的。在具体技术报告中，倒是有提到，使用 A800 加 SigInfer（中科加禾的产品），相比 vllm（加州大学伯克利分校两年前开源的一个加速推理的框架,目前依然是开源界的主流） 能效比可以提升 46%。但是具体细节讲的比较少，只提到提到的 KV Cache 的复用优化， 数据的 sequence 维度上也进行了并行划分等。这些方法比较常规，没看到比较新的idea或者其他值得关注的细节。

### 我的一些想法

这个工作我是特别关心的，如果能真正应用，可以很大的程度上解决卡脖子问题。我现在的想法总有点偏负面，可能是看了太多的信息，然后发现大部分都是瞎吹，所以现在习惯性带着质疑的眼光去看待这类新鲜事物。折腾半天，硬是没找到技术上的亮点，那只能说让子弹飞一会儿。



# 7.28

## LLAMA3的发布

本周最大事情莫过于LLama3的发布，目前行业内闭源模型是领先开源模型的，而llama3已经可以与行业中领先的模型竞争甚至领先。

具体的技术细节可能还要一定时间才能披露。模型的大小最大已经来到405B（作为参考，llama2最大是72b，chatgpt3.5是30~40b预估），只能说目前堆算力还没到极限。

### 我的一些想法

llama3发布冲击最大的肯定还是不在头部的闭源大模型，因为大家可以通过“蒸馏”等一系列方式“抄作业”，迅速完成追赶，本身像商汤科技这样的独角兽公司，做的就是toB的业务，希望通过模型的性能优势成为卖点。



## 实地考察以及一些交流杂谈

这周（以及上周）我去了上海，杭州，与一些朋友进行了交谈，参观了一些公司，机构，高校的实验室等。

对所了解到的情况进行一些简单分类。

1.做模型，开发产品：例如字节豆包AI，阿里qwen系列等，基本都是大公司的手笔，或许各家的技术有些参差，但是需求逻辑上都是打通整个链路，大模型即在B端作为生产力工具，也用作C端产品或者直接提供接口服务收费。

2.面向B端：例如零一万物，商讨科技。现在还在烧融资的钱，还没实现盈利。做的事情基本都是搞模型，刷榜，对其他公司提供大模型产品支持，本身不具备面向C端的盈利。

3.纯跟风，追热点：比如我实地去了的深信服，北大信研院等。感觉上面的领导都没想清楚要干啥，但是还是养了一个大模型团队，除了PPT吹一下也没看见什么产出，明眼人一下子就能看出来。可能就是被多方位投资一下

4.存粹为了发论文，骗经费等

5.AIGC面向产品：例如B站。这类公司在自己的产品上能用到大模型，但是本身去研究大模型在成本上不划算，主要做的就是在自己的产品上对接API。

从AI for Science角度去分析，C端的需求远远不足以支持这么多提供服务的公司，开源模型也会冲击本身的竞争力，2类公司可能会面临生存挑战；3.4类没啥好说的；5类公司没有本身的核心技术力；唯一有可能的是1类公司，我觉得是先有实践才有规范，先有了能够超过当前AI范式的一系列智能产品，然后从这些产品的共性上提炼才是新的AI范式。当然，等产品都出来了也没啥可研究的了。理论指导实践，实践在探索中反复修改理论，AI for Science的内涵也是在螺旋中充实，丰富。

# 9.1

## 目前实习情况

​    我是在企业信息服务部，做基础服务支持，比如数据中等，支付中台等。目前整个部门是做ToB的存量业务，每个版本迭代一点功能，主要关注日活，用户付费等指标。百度的技术沉淀还不错，有很多自研架构，技术栈，工具等，也是在企业项目理解高并发高可用的一些实践方法。实习的话，不算有压力，每天在公司的时间挺长，早10晚8，不过我一大半时间在看文档或者自己研究研究，实习还是学习为主，不能做那种简单的业务把时间全部占掉了。

## AI原生应用

​    目前百度高层在AI方向提的最多的是AI原生应用，CTO（首席技术官）许多演讲报告的观点，我精炼成一句话就是：“基底模型做起来费时费力不好讨，做好AI应用的商业变现才是正途”。

​	按我的理解：公司战略是打算对很多应用进行重构，这也就是所谓的AI原生应用，指在AI技术给产品赋能带来竞争力，然后抢占市场，通过市场优势，用户反馈来调整应用，来达到正向循环，谓之AI原生“数据飞轮”。嗯，只能说想法很好，这种想法应该每个公司都有，做不到人有我优肯定成不了事。

​	从经济链角度分析，百度仍然才进行战略搜索，市值300多亿美元，账上现金流都有1000多亿，明摆着就是不想冒风险，只不过不能愣着啥也不干，在AI的投入上和Google，meta比太少了，嘴上喊着使劲，心里使劲盘算性价比。

## 如流助手内部版

​	提到比较好的AI原生应用，百度内部的入流助手使用体验确实达到了一个很不错的程度。

​	从技术原理上来讲，没有颠覆性的东西，整体上是插件式开发，在文心一言的基础上加入了内搜插件，生活服务插件，邮件，如流等。然后其他的都是工程化处理的技术。

​	可以实现多种问题的一站式解决，比如: "帮我预约明天上午和xxx的会议"，助手会继续询问，具体几点，根据现有日程给出建议，询问还要通知哪些人，是否就近预约会议室等，然后可以在对话中完成对参会人员的消息通知，会议室系统的预约等。

​	从产品设计的理念来讲，就类似于智能管家，可以协调多个系统，本质上是一个统一的调度系统，不同的AI插件构成，但从用户角度来讲就是无所不能的人工智能。这个idea不算新颖，很早就有这种说法了，不过目前市面上还没有这种成熟的应用。

## 目前的困境

​	显然，GPT模式的热度已经降了很多，最热的时候应该是2023.3~9月，今年热度整体都少了很多。大家否定了很多方向，但是也没能真正走出新的，正确的方向，把模型做大，多模态，领域调优，量化这种都只能算在原有的道路上多走了几步。现有的基于transformer离通用人工智能差别还是太大，目前就是一部分拿着钱研究，挖坑填坑；一部分研究商业化变现。就算很多人知道这样不是正确的路，但是找不到更好的路，干巴巴的喊这样不对意义也不大。只能说顺应时代发展的自然规律，新的事物诞生，旧的事物灭亡需要时间的流逝。



# 9.8

## 自动驾驶体验

体验了一下萝卜快跑的自动驾驶，单纯从乘客的角度来说还是很不错的，车开的特别稳，加速减速，过弯等都特别的顺滑，像开车求稳的老司机。

不过目前问题还是比较多的，首先只能在主干路上进行，主要原因有二，其一是面对一些特殊情况，在训练和测试没考虑到的有未知的风险；其二是部分硬件的准确率达不到100%（正常有人车辆也达不到），程序做不到像人一样的随机应变。

## AI原生应用--法行宝

[法行宝-您的免费AI律师 (baidu.com)](https://ailegal.baidu.com/)

本质上，属于知识图库+领域大模型的应用。这是实习所在团队运维的一个项目。

整体的技术逻辑比较简单，从数据上游获取了大量的法律案例，当用户提问时，通过大模型给出建议，并且给出相似案件/判例的参考，后续会持续引导更加具体的分析问题。商业逻辑上，给出的参考案例中除了前几个案例，后面的更多案例会引导开通会员，引导用户付费。说到底，核心竞争力就在案例的数据，大模型对话引导的机制目前市面上的应用差距不会很大了。

商业化变现还在起步阶段，用户付费支持全案例解锁和部分类型解锁，目前付费用户绝大部分都是婚姻财产纠纷。。。可能目标群体都是18~30岁的人，面对的主要问题都在这方面。

## 一些想法

技术和市场是有些时候是有点割裂的，学习屠龙术，但是世界上本没有龙。目前大模型的交互能力，准确度的提升带来的价值挺难应用的。当然从科研的角度上来说只管研究就行，工程化商业化交给其他方面的人，但是也正是这样的想法去分割任务，现在科研很多研究都很“虚”，直观吹谁更牛，更新颖，让一些真正有价值的想法对比起来显得平庸，埋没在茫茫之中。学而不思则罔，死而不学则殆，工程和科研也是一样，只有科研无工程则虚无缥缈，只有工程不科研则停滞不前。

# 9.22

## 朱纯松团队的研究

#### 先说我给出的结论：

朱老师的研究是很有创造力的，虽然目前没有实质性的成果，但值得我们参考。

#### 首先

朱老师并不是创造了一个通用性人工智能，而是根据现有的不足，描绘了通用型人工智能应该有的东西。也就是找到了一个方向，而路怎么走还需要大家一起探讨。

#### 第二，讲讲我对UV系统的理解。

U代表社会规范，V代表个人需求，社会系统中的每个人都受到多个维度的社会关系所约束，可以表达为U系统中的各种势能函数；同时每个人也受各种欲望的驱动，可以表达为V系统中定义在各种子空间与维度的价值函数。AI会在价值函数和势能函数的驱动下，在满足社会需求，和个人平衡中达到一个最优点（AI自认为的最优，也就是我们需要优化的地方）。

通过改变环境，或者各项权重，来使AI改变，进化。举一个简单例子，社会规范要求AI遵纪守法，乐于助人；个人欲望包含金钱，权力；

AI就会在这两者的驱动下做出选择，如果金钱欲望很高，遵纪守法的驱动很小，就可能会违法获取金钱。通过设置不同的价值函数和势能函数，AI会趋向不同的选择。理想状态下是模拟现实世界，达到“心”与“理”的平衡的境界。

至于反向处理，从理论上来讲已经包含了，驱动肯定是包含了正面和负面。

#### 第三，优越性和值得参考的地方。

朱老师说到了通用性人工智能应该有的三个要素，实现无限任务，自主生成任务，价值驱动和对齐。这三点从字面上就能基本理解，AI要能自己探索，一直探索，并且和人类利益一致。我倾向于这是朱老师基于现在GPT的不足提出的，仔细想想肯定还是不够完备。比如说生成任务，实现任务的效率?是否会想办法突破自己？不然，我生成一个AI一直搬砖，也算是符合全部条件了。

朱老师也做了一些实验，例如**设置了一个小房间，有冰箱，床，电视等，AI可以从冰箱获取食物，从床上获取休息，电视中获得愉悦。在实验室中，没有给AI预设行为，而是通过饥饿度，疲劳度，愉悦度去约束，让AI自主探索行为，学会了开冰箱，睡觉，看电视等操作。**实验结果表明，AI能相当于一个9岁小孩的智商（没看懂这个实验结果怎么出来的）。

目前的GPT系列都是基于数据，无法给出超出数据范围的内容。而朱老师给出的方式基于价值，通过AI的价值驱动，去自主探索，自主评判，理论上有突破人类知识边界的可能。

#### 第四，局限性和不足。

整个框架需要填充的东西还比较多，只是一个不错的设想。其中困难较多，难以实现，能带来的收益不明，很难有研究者愿意投入其中去发展。

这就是一个具体和抽象的矛盾，我们常常说要从事物上面总结经验，形成更加一般化的道理，更好的指导方向。但是学习过于抽象的道理，又很难理解其精髓，遇到问题很难应用。

回到上述加粗的实验描述，这种实验太简单，哪怕穷举都能实现，在更复杂的情况下不一定适用。我举一个例子，吃不同的东西可以带来饱腹感这个反馈是即时的，但是也有营养成分，这个反馈比较长周期，往往我们都不知道结果，那AI会怎么选呢？会吃任何东西之前都先算一下吗？又从何处获得这些信息呢？是获取全部信息，还是抓大放小？获取信息和选择也有成本，AI如何选择？

所以，朱老师也就是找到了一个实现通用人工智能方向，而路怎么走他走出了一步，即使充满各种不足。

## 当下的想法

目前看了这么多，还是没有太好的想法，当下只能慢慢吸取别人思想，自己也多多思考。十全十美肯定不可能，我的目标是拿出一个说得过去，有一定亮点的思路，能够向前走几步就算成功。

## 杨伊宁那边的问题

她的问题不仅仅是实验结果不对，而是缺乏整体的一个思考逻辑，很多基本概念都没清楚，所以思路都是混沌的。她的需求是用强化学习做一个文章选择的智能体，希望能模拟正常人类偏好去选择不同长度，题材等因素的文章。我给他捋了一遍整体的思路，给了一些思考的方向。她说计划读博士，所以想好点做，所以我推荐了一些学习资料，一些基础概念先打好。

目前是每周简单沟通一下，在我能力范围内解答一下她的问题。我也不会去push，主要还是看她的主动性。从当下的情况来看，主动性不是很足，挺大概率她会放弃。



# 9/29

# 回答上次的提问

我理解内驱内容产生机制的部分，朱老师想法上肯定是希望“人类根据社会环境，人类思考个人生命的意义”这样的方式去产生一个自己的目标，或者说价值体系，然后基于这个价值体系去驱动自己的行为。论文1有相关描述

> The later evolution of humankind has witnessed a diversity of values, e.g., altruism, honesty, beauty, courage. Each individual is driven by a complex value system that is shaped by his ongoing interaction with the physical and social world. A similar idea of a value system can be incorporated to create generally intelligent agents and served as an engine for agents to generate appropriate new tasks based on a predefined value system. In this case, artificial intelligence can be aligned via value alignment instead of a predefined step-by-step instruction for tasks.
>
> 机翻：
>
> 人类后来的进化见证了价值观的多样性，例如利他主义、诚实、美丽、勇气。每个人都受到一个复杂的价值体系的驱动，这个价值体系是由他与物质和社会世界的持续互动所塑造的。可以结合价值系统的类似想法来创建一般智能的代理，并作为代理的引擎，根据预定义的价值系统生成适当的新任务。在这种情况下，人工智能可以通过值对齐来对齐，而不是通过预定义的任务分步指令。

不过这只是想法，实际上他做的实验也体现不出来这种东西，纯粹从实验的角度来看，就成了收益平衡，当然这个实验也不是什么论文里面截取的，只是他报告里面提到的。

> 朱老师也做了一些实验，例如设置了一个小房间，有冰箱，床，电视等，AI可以从冰箱获取食物，从床上获取休息，电视中获得愉悦。在实验室中，没有给AI预设行为，而是通过饥饿度，疲劳度，愉悦度去约束，让AI自主探索行为，学会了开冰箱，睡觉，看电视等操作。实验结果表明，AI能相当于一个9岁小孩的智商（没看懂这个实验结果怎么出来的）。

朱老师团队比较复杂，回国之前是加州大学洛杉矶分校的教授那边的团队，回国之后原来的团队肯定还有一定的持续产出，之前在北大通用人工智能研究院有一些合作项目，目前是清华大学通用人工智能研究院的院长（这个研究院还没有建立起来）

团队的论文研究，首先要确定的是，朱老师近三年没有1，2作论文，论文基本都是合作或者挂名，方向特别杂乱，包括但不限制于：具身人工智能，多模态大模型，强化学习，情感模型，通用人工智能的探讨。其他的方向就不说了，简单讲讲通用AI相关的一些研究。

# 论文研究

文章的思想已经在上次汇报中说过了，这次更加具体的研读一下

> 朱老师说到了通用性人工智能应该有的三个要素，实现无限任务，自主生成任务，价值驱动和对齐。

## [缸中之脑：大型语言模型中通用人工智能的缺失部分](https://arxiv.org/abs/2307.03762)

缸中的大脑，每个人的大脑都与身体分离，并由营养物质维持，让人们相信一切都像他们在现实世界中一样。普特南认为，由于无法将这些表示与现实世界的物体联系起来，即使能说话和写作，他们也无法理解单词的含义。例如，居住者声称自己是一个缸中的大脑，但在他无法理解“大脑”和“缸”的真正含义。LLM也是如此，分析海量文本语料库中的模式，以预测语言关系，生成反应因此，它们的输出仅限于训练数据，无法在符号和现实世界实体之间建立联系。

在LLM的发展过程中，引入了许多任务来衡量“智力”。包括数学计算，逻辑推理等。最后得出的结论是LLM在数据多的领域效果好，所以无法判断LLM是真正懂了知识还是仅仅通过分析海量数据生成答案。LLMs可以作为人类的有益助手——一个更个性化的百科全书，显然这种模式不是AGI（通用人工智能）。
作者提出认为AGI具有四个特征，包括

Agent可以执行无限的任务。

Agent可以在给定的上下文中自主生成新任务。

Agent由价值体系推动，是生成任务的基本架构。

Agent拥有一个世界模型，它代表了现实世界，并指导他们与世界的互动。

知识获取不仅依赖于被动输入，还需要反复试验和试错。至于怎么样去反复试验和试错，需要有一个标准，这个标准就是agent的价值观，这个价值体系是由他与物质和社会世界的持续互动所塑造的。被动输入知识是知，主动探索实验试错是行，要结合才能知行合一。





整篇文章最大的问题是没有实验结论，虽然在大模型能力那一块很多实验，但是都是引用的。最后提出的范式，探索试错并没有设计实验，自然也没有结论，类似于综述和理论分析之间。大概读了几篇，关于AGI的论文都是这样，其实朱老师的结论总结起来就是最开始那几句话，论文里面主要是引出这些的一些过程。



# 结论

deepseek系列大模型各项性能达到了业内领先，并有更低的推理成本。从技术上没有革命性创新，但有较大程度的优化。此外，deepseekv3和r1系列的发布对于商业模式和意识形态有很大影响。

接下来从以下几个方面展开叙述

## 1.deepseek和GPT系列的比较

deepseek这次火出圈主要是v3和r1版本，v3是通用版本，r1是深度思考版本相对v3使用了完全的强化学习，因此需要更多算力。

根据官网的介绍，DeepSeek-V3 多项评测成绩超越了 Qwen2.5-72B 和 Llama-3.1-405B 等其他开源模型，并在性能上和世界顶尖的闭源模型 GPT-4o 以及 Claude-3.5-Sonnet 不分伯仲，此外**自称训练成本不到GPT-4o的1/20**

首先性能上接近，可信度很高，包括最新推出的GPT-4o3min系列，公布的跑分依旧和DeepSeek-V3，R1系列不相上下；

其次，成本确实低了很多。但具体的数值有点夸张，比如自称训练成本不到1/20，其实是没有算试错成本的；提供对外的API价格只有GPT-o1的3%，但这一部分只是deepseek价格战策略的原因，open ai为了应对，新出的o3-min对应也降价了。所以实际运营成本，**我个人估计deepseek在GPT的20%～50%**。

> DeepSeek-R1 API 服务定价为每百万输入token  4 元（缓存未命中），每百万输出 tokens 16 元
>
> Deepseek v3每百万输入 tokens  1 元（缓存未命中），每百万输出 tokens 2 元
>
> o3-mini每百万token的输入（缓存未命中）1.10美元，输出价格为 4.40美元

## 2.deepseek对于开源闭源，意识形态，商业模式的影响

### 开源闭源

大模型一直有开源闭源的争论，开源的方面认为开源才能集思广益提供更多创造，闭源的认为大模型很烧钱，必须形成商业模式才能持续发展，在deepseek出现之前，闭源模型性能一直处于领先。

deepseek极大的缩小了开源和闭源模型之间的差距，open ai奥特曼指出，虽然OpenAI将在未来继续开发更先进的模型，但与DeepSeek相比，其当前的领先优势将大幅削弱。

开源模型一旦追上闭源模型，这对闭源模型的商业模式的冲击是巨大的（后面会提到），闭源模型想再次领先就困难了。

### 意识形态

长期以来，以美国为首的西方国家都在虹吸世界各处的人才，现在AI是科技实力的重要代表，deepseek后来居上这对西方国家的意识形态输出的打击是巨大的。

西方对中国模型本身并不放心，他觉得模型内部训练时就有了价值观偏见（当然我们对西方国家也有这样的顾虑）。因为生成类AI的输出风格和他的训练样本非常相关。大家都知道中国互联网基本处于一个封闭状态，西方人会对“模型自带的意识形态”产生害怕心理。而选择开源的话，就相当你把我模型的数据（不是训练模型的数据）下载下来放到自己的GPU上去跑，包括我们今天看到Amazon和英伟达的云服务器都支持了DeepSeek模型，就是因为它选择开源模式。部署到本机内部，西方也无所谓什么顾虑，不管什么价值观输出，至少不存在信息传回政府这种。

deepseek开源了，且足够优秀，那不可避免的会有很多国家和组织使用，西方国家长期宣传的“美国领先”也会收到更多的质疑。

### 商业模式

DeepSeek由金融机构幻方量化开发，能够在投研、量化交易、自动化交易等多个金融场景中进行自验证。做量化交易，和普通公司最大的不同，他们在“玩钱”，“玩杠杆”，是非常危险的事，从这种角度，做量化交易的人往往更脚踏实地，不会道听途说哪种算法好就拿来用，即使是Google，OpenAI发明的算法，它也会做非常非常多的修改。相反很多AI公司他们多是互联网所谓”大厂“思维 – 想着怎么用产品经理的思维把产品做大，然后去marketing，去PR。产品本身如何在其次，至少用广告打造、宣传让大家认为产品有前途。量化交易不是这种思维。通俗一点讲，目前各大互联网公司都在吹牛逼的技术，拿融资，所以各种刷榜发论文，其实忽略了模型本身的能力的打磨。当然deepseek发布后，各大模型又要洗牌，本身是一个开源模型大家肯定会在技术上查漏补缺立马跟上这是利好；deepseek打价格战，各个模型卖API接口的收益要大打折扣了，而且以后融资也也更难拿了，这是很大的冲击。

## 3.deepseek的技术创新点

选择性的看了deepseek官方的三篇论文，比较新颖的技术点还是mla和mtp，这两个技术显著的降低了训练和推理的成本

### 1）多头潜在注意力（MLA）——稀疏键值

传统的Transformer架构中的多头部注意力（MHA）的键值（KV）缓存对LLMs的推理效率构成了重大障碍，虽然有了分组查询注意力（GQA）和多查询注意力（MQA），但是这些方法在试图减少KV缓存时往往牺牲了性能

在传统的多头注意力机制中，对于每一个输入的token,我们需要在每一层的attention中存储它的键(key)和值(value)向量，以便后续的token可以通过查询(query)这些键值对来计算注意力权重

这些键值向量的总元素数量等于2nhdh，其中nh是注意力头的数量,dh是每个头的维度

当模型的层数、头数和维度较大时，这个缓存的开销非常大

与传统的注意力机制不同，MLA利用**低秩键值联合压缩方法**，在推理过程中通过将键值（KV）缓存压缩成潜在向量来大幅减少内存占用，从而提高推理效率；为了进一步提升性能，DeepSeek-V2对查询和键进行解耦，并为每个注意力头设置了独立的维度，以提高模型的表达能力

键值联合低秩压缩:将原本需要单独存储的键向量和值向量压缩到了一个维度更低的向量cKVt中,这个压缩后的向量维度为dc，远小于原来的2nhdh在推理时，我们只需要存储这个压缩后的cKVt向量，而不需要存储原始的键值向量



用通俗的一点话表达，就是把存储注意力头的信息的向量映射压缩到更低的维度了，所以存储空间小了训练速度快了。理论上这是会有一些损失的，类似于图片的有损压缩，比较低的损失换来很大的空间节省，但是本论文中损失没有具体表达，估计是不好计算。这个方法也不算完全原创吧，类似于lora微调都是利用这样的方法，不过在多注意力头这样用的，比较成功的大模型，deepseek确实是第一个，后面估计大家都会用了。

### 2）MTP多token预测

DeepSeek引入的多token预测(MTP)技术堪称一个Game Changer。这项技术实际上是Meta在2024年4月30号提出的，DeepSeek对新技术的应用甚至快过Meta自己。

语言模型一次只预测一个token的范式。它就像是让模型从"一字一句"地朗读，进化为"整句整段"地理解和生成。在训练过程中，模型不再局限于预测序列中的下一个token，而是学会同时预测多个连续位置的token。这种并行预测机制不仅提高了训练效率，还让模型能够更好地捕捉token之间的依赖关系。在保持输出质量的同时，模型整体性能提升2-3%。

### 3）DualPipe跨节点通信

DualPipe引入了双重流水线的概念，就像在同一条生产线上同时处理两批产品。当一个计算阶段在等待数据传输时，可以立即切换到处理另一批数据，这样就能充分利用原本的空闲时间。

涉及到的很多，就不一一介绍了。整体看起来deepseek其实没有太多技术创新，包括mtp，思维链，dual pipe，混合精度，SFT，RL的方法其实各个大模型都在用，并非deepseek原创。硬要说我觉得还是商业模式上的务实，很多技术都是走的远，比如mtp比提出它的meta走的更远。

## 4.deepseek与AGI的关系

前面其实也有提到，deepseek的贡献DeepSeek是站在前人0到1的基础上，比如思维链这种，他不是第一个提出来，但是它挖得比较深从1到了10，但deepseek本质上还是transformer系列基于数据的大模型，deepseek离AGI的距离和GPT离AGI的距离是一样的。

## 5.deepseek的部署和使用

虽然大模型的部署有一定门槛但没有研究的必要。

目前各大云平台都有镜像可以直接使用，需要本地使用也可以直接pull部署到本地（当然现在没卡，也没有这种需求）。直接使用就更简单了，开源模型使用基本都免费，直接官方网页端或者手机APP就行。



调查了一下**时空折叠技术**是实现 MTP（多token预测）的一种算法。上一篇报告中，我也解释了，我觉得MTP和MLA是deepseek能用更小的成本达到同等性能的关键。

> MTP改变了语言模型一次只预测一个token的范式。它就像是让模型从"一字一句"地朗读，进化为"整句整段"地理解和生成。在训练过程中，模型不再局限于预测序列中的下一个token，而是学会同时预测多个连续位置的token。这项技术实际上是Meta在2024年4月30号提出的，deepseek也用了这个思想，并改良了算法。

之前deepseek v3的论文发出来后，国外质疑deepseek抄袭，后面证明了**时空折叠技术**是原创

其实具体怎么做的论文中描述的并不是很清楚，我觉得正是因为这样别人才会质疑（毕竟是核心机密不会那么轻易告诉别人，目前deepseek参数开源了但是训练过程没开源）以下是deepseekv3论文中关于mtp算法的描述：

原文在 附件论文2.2 Multi-Token Prediction

> DeepSeek V3创新引入**残差流分形解码架构**（也就是网传的时空折叠技术）： 
>
> 1. **主预测模块**：输出当前token概率分布（标准模式） 
>
> 2. **次预测模块**：将最终残差流注入轻量化 Transformer 子块，生成次 token 预测 
>
> 3. **动态损失融合**：主次预测损失以 7:3 权重混合训练，兼顾精度与前瞻性 
>
>    论文中的结论：该设计使单次前向传播学习效率提升 1.8 倍，在代码补全任务中，token 预测准确率相对位置误差降低 42%。

单从这些看起来确实有抄袭嫌疑，后面应该是提供了有力的证据证明了算法的创新，但是这个证明目前还没披露。

